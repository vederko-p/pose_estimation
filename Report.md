# Введение

Основная задача состоит в обнаружении людей на видеопотокое путем определения их позы - Pose Estimation. Данная задача может быть как обособленной, так и являться дополнительным источником информации в решении других задач, так как предоставляет геомтерическую информацию и информацию о движении тела человека. Так, например, работая с маленькими объектами, определение частей тела человека может помочь выделять необходимые области, такие как голова или руки, с большей точностью, для дальнейшей их классификации на "защищенные" и "не защищенные" участки тела.

В данной работе рассматриваются trainable end-to-end подходы к решению задачи.

# Pose Estimation

## Постановка задачи

В общей формулировке задача определения позы человека заключается в детекции его суставов на изображении. Однако уточнение ключевых точек может варьироваться от модели к модели. Так, например, в рамках модели [Google MediaPipe](https://google.github.io/mediapipe/solutions/pose.html) в качетсве целевых точек на теле человека выступают следующие:
![[Pasted image 20221115093025.png]]
Reference: https://google.github.io/mediapipe/solutions/pose.html

У другой модели - [YoloPose](https://arxiv.org/pdf/2204.06806.pdf) точки несколько отличаются:
![[Pasted image 20221115093317.png]]
Reference: https://learnopencv.com/yolov7-pose-vs-mediapipe-in-human-pose-estimation/

У задачи определния позы человека есть несколько классификаций.

С точки зрения количества объектов:
* Single person pose estimation
* Multi person pose estimation

Как правило, задача, предусматривающая множество обектов (multi person) является наиболее сложной, чем вариант с одним объетом ввиду большого количества препятствий:
* Различное число людей от изображения к изображению
* Различные размеры людей
* Перекрытия частей тела
* и другие

С точки зрения размерности пространства:
* 2D person pose estimation
* 3D person pose estimation

## Метрики

Тяжело однозначно рассчитать качество модели определения позы ввиду того, что должно быть учтено множество различных факторов:
* верхняя/нижняя часть тела
* single/multiple
* размер тела
* и другие
Как правило используется несколько метрик.

### Percentage of Correct Parts (PCP)
Reference: https://www.robots.ox.ac.uk/~vgg/publications/2012/Eichner12/eichner12.pdf

Данная метрика определяет точность локализации конечностей. Локализация конечности считается верно определенной, когда расстояние между предсказанной точкой сустава и действительной меньше, некоторой доли длины конечности (между $0.1$ и $0.5$).

Чем данный показатель выше, тем модель работает лучше.

### Percentage of Correct Keypoints (PCK)
Reference: https://www.cs.cmu.edu/~deva/papers/pose_pami.pdf

Дання метрика также используется для измерения точности локализации различных ключевых точек в рамках заданного порога близости. Порог устанавливается равным половине длины сегмента с головой для каждого тестового изображения и определяется как $PCKh@0.5$. $PCK@0.2$ определяется порогом, равным $0.2$ части от диаметра торса (расстояние от начала шеи, до таза).

Чем выше значение данной метрики, тем лучше.

### Average Precision (AP) and Average Recall (AR)
Reference: https://www.cs.cmu.edu/~deva/papers/pose_pami.pdf

Предсказанная точка считается корректной $(TP)$, если лежит от действительной точки на расстоянии не дальше, чем $\alpha \max(h, w)$ пикселей, где $h, w$ - пространтсвенные размеры бокса в пикселях, $\alpha$ - контролирует относительный порог.

### Object Keypoint Similarity
Reference: https://stasiuk.medium.com/pose-estimation-metrics-844c07ba0a78

Данная метрика определяется как расстояние между предсказанными точками и действительными, нормализованное на размер человека:

$$ OKS = \exp\left(-\dfrac{d_i^2}{2s^2k_i^2}\right), $$

$d_i$ - евклидово расстояние между действительной точкой и предсказанной
$s$ - scale - квадратный корень из размеров области объекта
$k$ - по-точечная константа, оценивающая важность каждой точки

Константы для точек тела, расчитанные исследователями из COCO:

keypoint | $k_i$
:-:|:-:
hips|$0.107$
ankles|$0.089$
knees|$0.087$
shoulders|$0.079$
elbows|$0.072$
wrists|$0.062$
ears|$0.035$
nose|$0.026$
eyes|$0.025$

$OKS$ метрика играет ту же роль, что и $IoU$ в задаче детекции объектов и используется в $AP$ и $AR$.

## Функции ошибки
Reference: https://arxiv.org/pdf/2204.06806.pdf

Функции ошибки зависят от типа модели и варьируются от одной модели к другой. $OKS$ - наиоблее популярная метрика для оценки качества нахождения ключевых точек. Традиционно некоторые подходы использую $L_1$ loss для обучения детектированию ключевых точек. Однако $L_1$ loss не обязательно подходит для достижения оптимального $OKS$. $L_1$ является наивным и не учитывает масштаб объекта или тип ключевой точки. В качестве функции потерь $OKS$ применима только к задаче регрессии. В случаях вероятностных моделей выбор данной функции потерь будет некорректным.

В отличие от обычной $IoU$ ошибки, которая подвержена затуханию градиентов в случае не пересекающихся боксов, $OKS$ loss никогда не сталкивается с плато.

Модель YoloPose обобщает идею $IoU$ с боксов на ключевые точки. $OKS$ воспринимается как $IoU$ в случае ключевых точек. По существу $OKS$ loss является инвариантной относительно масштаба и дает одним ключевым точкам больший вес, нежели другим. Например, ключевые точки на голове человека (глаза, нос, уши), штрафуются сильнее за одну и ту же ошибку расстояния в пикселях, чем ключевые точки на туловище человека (плечи, колени, бедра).

В соответсвии с каждым боксом хранится вся информации о позе. Следовательно, если истинный бокс совпадает с $k$-ым якорным боксом в координатах $(i,j)$ и масштаба $\Large{s}$, то реализуется предсказание ключевых точек относительно центра якорного бокса. $OKS$ вычисляется для каждой ключевой точки отдельно и затем суммируется в итоговую $OKS$ ошибку или keypoint $IoU$ loss:

$$
\Large{\mathcal{L}_{kpts}(s,i,j,k)}=
1-
\sum_{n=1}^{N_{kpts}}{OKS} =
1 - \frac
{
	\sum_{n=1}^{N_{kpts}}{
		\exp\left({\frac{d_n^2}{2s^2k_n^2}}\right)\delta(v_n>0)
	}
}
{
	\sum_{n=1}^{N_{kpts}}{
		\delta(v_n>0)
	}
},
$$

$d_n$ - Евклидово расстояние между предсказанным и действительным положением для $n$-ой ключевой точки
$k_n$ - соответсвующие ключевым точкам веса
$s$ - масштаб объекта
$\delta(v_n)$ - флаг видимости для каждой ключевой точки

Для каждой ключеой точки обучается параметр уверенности, который показывает, представлена ли ключевая точка для найденного человека или нет. Здесь флаг фидимости для ключевой точки используется как истинное значение:

$$
\Large{\mathcal{L}_{kpts\_conf}(s,i,j,k)}=
\sum_{n=1}^{N_{kpts}}{
	BCE(\delta(v_n>0), p_{kpts}^n)
},
$$

$p_{kpts}^n =$ предсказанной уверенности для $n$-ой ключевой точки
$BCE$ - Binary Cross Entropy

Ошибка в точке $(i,j)$ валидна для $K$-го якорного бокса масштаба $\Large{s}$, если истинный бокс совпадает с этим якорным боксом. Наконец, общая ошибка суммируется по всем масштабам, якорным боксам и позициям:

$$
\Large{\mathcal{L}}_{total}=
\sum_{s,i,j,k}{
	(\lambda_{cls}\mathcal{L}_{cls}
	+ \lambda_{box}\mathcal{{L}}_{box}
	+ \lambda_{kpts}\mathcal{L}_{kpts}
	+ \lambda_{kpts\_conf}\mathcal{L}_{kpts\_conf})
},
$$

$\lambda_{cls}=0.5$, $\lambda_{box}=0.05$, $\lambda_{kpts}=0.1$, $\lambda_{kpts\_conf}=0.5$ - гиперпараметры, выбранные с целью баланса медлу ошибками разных масштабов.

## Подходы к построению моделей

Большинство существующих алгоритмов определния позы можно разбить на две группы:
* сверху-вниз
* снизу-вверх

Top-down [8], [12], [13], [19], [20], [21]
Методы типа сверху-вниз сначала применяют к изображению детектор людей, а затем для каждой детекции человека решают задачу поиска его ключевых точек. Вычислительная сложность такого подхода увличивается линейно с увеличением числа людей на изображении.

Bottom-up approaches [4], [5], [14], [23], [25]
Методы типа снизу-вверх сначала находят ключевые точки на изображении, а затем объединяют их в отдельных людей. Большинство данных методов работаю практическит за константное время на этапе поиска ключевых точек, однако используют вычислительно сложные методы для на этапе группировки точек в отдельных людей.

На данный момент также развиваются и подходы на основе модели YOLO - single-shot детектора, в которых стремятся объединить два подхода, описанных выше, и исключить их недостатки.



# Reference
[Deep Learning-Based Human Pose Estimation: A Survey](https://arxiv.org/pdf/2012.13392.pdf)

Перетащить из метдов и разбить на блоки